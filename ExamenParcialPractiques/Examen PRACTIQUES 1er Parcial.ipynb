{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer Parcial 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercici 1**\n",
    "\n",
    "### Sistemes de Recomanació\n",
    "\n",
    "**Creació de les dades**\n",
    "\n",
    "Crea un dataframe amb les dades que es mostren a continuació, incloent els nom de files i columnes.\n",
    "\n",
    "Les dades indiquen el nombre de reproduccions de pel·lícules per a diferents usuaris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='dades.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementa (anomena \"df\" a la variable que conté el DataFrame):\n",
    "\n",
    "# df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per tal de poder recomanar és imprescindible definir una funció de similitud entre vectors. \n",
    "\n",
    "Siguin $x$ i $y$ dos vectors, implementa les següents funcions de similitud:\n",
    "\n",
    "1) **Correlació de Pearson**:\n",
    "\n",
    "$${\\displaystyle sim(x,y)={\\frac {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}{{\\sqrt {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}}}{\\sqrt {\\sum _{i=1}^{n}(y_{i}-{\\bar {y}})^{2}}}}}} \\in [-1,1] \\\\ \\text{On }\\bar{x} = \\frac{1}{n} \\sum^n_i x_i\\text{ la mitja (i anàlogament per }y\\text{)}$$\n",
    "\n",
    "2) **Similitud cosinus**: \n",
    "\n",
    "$$sim(x, y) = \\frac{x\\cdot y}{||x||\\hspace{0.1cm} ||y||} \\in [-1,1]  \\\\ \\text{On }||x||\\text{ indica la norma de }x\\text{ (i anàlogament per }y\\text{)}$$\n",
    "\n",
    "Notes:\n",
    "\n",
    "- **Recorda que no pots fer servir bucles ni funcions que retornin directament el resultat**.\n",
    "\n",
    "- Les dues mètriques no tenen perquè donar el mateix valor pels mateixos vector.\n",
    "\n",
    "- Pots considerar que no hi ha NaNs en els vectors, han estat substituïts per 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(x,y):\n",
    "    \"\"\"\n",
    "    Retorna la correlació de Pearson de dos vectors n-dimensionals.\n",
    "    Pels casos on el divisor sigui 0, retorna 0.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la correlació de Pearson\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(x,y):\n",
    "    \"\"\"\n",
    "    Retorna la similitud cosinus de dos vectors n-dimensionals.\n",
    "    Pels casos on el divisor sigui 0, retorna 0.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la similitud cosinus\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 1, 1, 0., 2])\n",
    "y = np.array([1, 2, 3, 0., 0.])\n",
    "print(pearson(x, y))\n",
    "print(cosine(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els usuaris reprodueixen en diferent mesura els items, uns més cops, d'altres menys. Fent servir la següent formula, heu d'escalar la predicció a la mitja de l'usuari.\n",
    "\n",
    "La predicció d'un item $i$ per a un usuari $u$ vindrà donada per:\n",
    "\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\bar{r_u} + \\frac{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)\\cdot (r_{p,i}-\\bar{r_p})}{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)}$$\n",
    "on $r_{p,i}$ són les reproduccions de l'usuari $p$ per la pel·lícula $i$, $\\bar{r_u}$ és la mitjana de reproduccions de l'usuari $u$ i, similarment, $\\bar{r_p}$ la mitja de reproduccions de l'usuari $p$.\n",
    "\n",
    "Recordeu que únicament heu de tenir en compte les similituds d'aquells usuaris que hagin reproduït les pel·lícules. Implementeu-ho sense bucles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item, df, similarities):\n",
    "    \"\"\"\n",
    "    Utilitzant les similituds i el nombre de vegades que un usuari ha reproduït un ítem\n",
    "    calcula segons la fórmula anterior el valor de recomanació\n",
    "    \n",
    "    No és necessari que consideris una matriu triangular.\n",
    "    No facis servir bucles.\n",
    "    \n",
    "    Si ho necessites, pots fer conversions d'ID a fila/columna amb\n",
    "    df.index.get_loc(id) i df.columns.get_loc(id)\n",
    "    \n",
    "    :param user: ID de l'usuari per la predicció\n",
    "    :param item: ID de l'ítem per la predicció\n",
    "    :param df: Dataframe que conté el nombre de vegades que un usuari \n",
    "        ha reproduït una pel·lícula\n",
    "    :param similarities: Matriu de similituds\n",
    "    :return : Retorna un escalar (float) amb la predicció\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquesta matriu de similitud **no** correspon amb les dades intencionadament. Feu-la servir per al següent exercici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = np.array([[0.        , 0.37510523 , 0.42534257],\n",
    "                         [0.37510523, 0.        , 0.86862112],\n",
    "                         [0.42534257, 0.86862112, 0.        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction('Bob', 'Star Wars', df, similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercici 2\n",
    "\n",
    "### Optimització"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A les pràctiques hem vist com arribar al mínim d'una funció. Ara el que volem es poder trobar mínims o màxims amb el mateix procés iteratiu.\n",
    "\n",
    "Per resoldre aquest problema considerarem la direcció de cerca donada pel **mètode de Newton**.\n",
    "\n",
    "En aquest exercici es demana que implementeu aquest mètode.\n",
    "La modificació que caldrà fer respecte a l'algorisme del descens del gradient vist a classe (en una dimensió) ve donat per l'equació iterativa:\n",
    "\n",
    "$$x^{k+1} = x^{k}-\\alpha^{k} \\frac{\\partial f(x^{k})}{\\partial^2 f(x^{k})}$$\n",
    "\n",
    "Que caldrà repetir fins a arribar a un màxim d'iteracions o fins que $|x^{k+1} - x^{k}|< eps$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per tal de comprovar la correcta implementació del mètode de Newton es donen les funcions $f_1$ i $f_2$ i les seves derivades.\n",
    "\n",
    "$$f_1(x) = x^2$$\n",
    "\n",
    "$$ \\frac{\\partial f_1}{\\partial x} = 2x $$\n",
    "\n",
    "$$ \\partial^2 f_1(x) = \\frac{\\partial^2 f_1}{\\partial x} = 2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1 ( x ):\n",
    "    return x**2\n",
    "\n",
    "def df1(x):\n",
    "    return x*2\n",
    "\n",
    "def d2f1(x):\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f_2(x) = x^3 - 2x + 2$$\n",
    "\n",
    "$$ \\frac{\\partial f_2}{\\partial x} = 3x^2 -2$$\n",
    "\n",
    "$$ \\partial^2 f_2(x) = \\frac{\\partial^2 f_2}{\\partial x} = 6x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2 ( x ):\n",
    "    return x**3 - 2*x + 2 \n",
    "\n",
    "def df2(x):\n",
    "    return 3*x**2 - 2\n",
    "\n",
    "def d2f2(x):\n",
    "    return 6*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descend_Newton(grad, grad_2, x, alpha, eps=1e-6, max_iters=1e2):\n",
    "    \"\"\"\n",
    "    Aquesta funció implementa l'algorisme de Newton, \n",
    "    és a dir, donat un punt inicial, el gradient, la segona derivada i el pas, intenta \n",
    "    trobar el mínim o màxim de la funció seguint l'equació iterativa anterior.\n",
    "    \n",
    "    :param grad: Primera derivada de la funció\n",
    "    :param grad_2: Segona derivada de la funció\n",
    "    :param x: Punt inicial\n",
    "    :param alpha: Pas de cada iteració\n",
    "    :param eps: Moviment mínim realitzat abans de parar\n",
    "    :param max_iter: Iteracions màximes a realitzar\n",
    "    :return: La funció retornarà una llista/tupla amb:\n",
    "        * Una np.array, amb shape [X], que contingui el punt inicial més els punts on s'ha mogut a cada iteració. \n",
    "            X és el nombre d'iteracions fetes + 1\n",
    "        * Punt final, mínim o màxim trobat\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "X = np.arange(-5, 5.01, 0.1)\n",
    "x0 = np.random.uniform(-4, 4)\n",
    "points, final_point = gradient_descend_Newton(df1, d2f1, x0, 1)\n",
    "fig = plt.figure()\n",
    "plot_gradient_descend_1d(f1, X, points, minimum, fig)\n",
    "\n",
    "print('f1({}) = {}'.format(final_point, f1(final_point)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "X = np.arange(-4, 4.01, 0.25)\n",
    "x0 = np.random.uniform(-4, 4)\n",
    "points, final_point = gradient_descend_Newton(df2, d2f2, x0, 1)\n",
    "fig = plt.figure()\n",
    "plot_gradient_descend_1d(f2, X, points, minimum, fig)\n",
    "fig.gca().set_ylim([-20, 20])\n",
    "\n",
    "print('f2({}) = {}'.format(final_point, f2(final_point)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
